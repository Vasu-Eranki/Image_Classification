# -*- coding: utf-8 -*-
"""Cifar_100

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u29E0XhuAsjl1oMweGr3ToLDj4cf5ox-
"""

import tensorflow as tf
from tensorflow.compat.v1 import keras 
from tensorflow.compat.v1.keras import layers 
print(tf.VERSION)
print(tf.keras.__version__)

(xtrain,ytrain),(xtest,ytest)=tf.compat.v1.keras.datasets.cifar100.load_data(label_mode='fine')
xtrain=xtrain/255
xtest=xtest/255
#training = tf.compat.v2.data.Dataset.from_tensor_slices((xtrain,ytrain))
#testing = tf.compat.v2.data.Dataset.from_tensor_slices((xtest,ytest))
#training = training.batch(64).shuffle(buffer_size=64)
#testing = testing.batch(64).shuffle(buffer_size=64)
#training = training.prefetch(tf.data.experimental.AUTOTUNE)
#testing = testing.prefetch(tf.data.experimental.AUTOTUNE)

model = tf.compat.v1.keras.Sequential()
model.add(layers.Conv2D(filters=64,kernel_size=4,strides=2,padding='valid',use_bias=True,input_shape=(32,32,3)))
model.add(layers.BatchNormalization())
model.add(layers.Activation(tf.nn.leaky_relu))
model.add(layers.Conv2D(128,4,2,'valid',use_bias=True))
model.add(layers.BatchNormalization())
model.add(layers.Activation(tf.nn.leaky_relu))
model.add(layers.Conv2D(256,1,1,'valid',use_bias=True))
model.add(layers.BatchNormalization())
model.add(layers.Conv2D(256,1,1,'valid',use_bias=True))
model.add(layers.Flatten())
model.add(layers.Dense(100,activation='softmax'))

model.compile(optimizer='Adam',loss=tf.compat.v1.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])
print(model)
print(model.summary())
model.fit(xtrain,ytrain,batch_size=64,epochs=50,verbose=1,shuffle=True)

test_loss,test_accuracy = model.evaluate(xtest,ytest,verbose=1)
print(test_accuracy)
print(test_loss)